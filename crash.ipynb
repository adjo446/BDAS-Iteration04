{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFOSYS 722 - BDAS ITERATION\n",
    "\n",
    "# Predicting Crash Severity On New Zealand Roads\n",
    "\n",
    "Ferdinand Djohar (adjo446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREREQUISITES\n",
    "Initialise and start spark session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('bdas').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA UNDERSTANDING & DATA PREPARATION\n",
    "\n",
    "### 2.2 Data Description\n",
    "Data set consist of 104,032 records in total, sourced from three CSV files (i.e. one file for each year) with 38 attributes.\n",
    "\n",
    "Documentation provided by NZTA tells us that most of the value types in the data set are categorical and numeric types. Some variables are derived from other variables e.g. **URBAN** variable is derived from **SPD_LIM** variable giving possible values of *'Urban'* where **SPD_LIM** is less than 80 or *'Open Road'* where **SPD_LIM** is greater or equal to 80.\n",
    "\n",
    "Please refer to *Appendix A* in the report for more detailed list of attributes of the data set extracted from NZTA documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104032\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"Data/*.csv\", header = True, inferSchema = True)\n",
    "\n",
    "# Print out the dimension of the data frame\n",
    "print(df.count()) #rows\n",
    "print(len(df.columns)) #columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View first few records of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRASH_YEAR</th>\n",
       "      <th>CRASH_SEV</th>\n",
       "      <th>MULTI_VEH</th>\n",
       "      <th>HOLIDAY</th>\n",
       "      <th>LG_REGION_DESC</th>\n",
       "      <th>EASTING</th>\n",
       "      <th>NORTHING</th>\n",
       "      <th>CRASH_LOCN1</th>\n",
       "      <th>CRASH_LOCN2</th>\n",
       "      <th>OUTDTD_LOCN_DESC</th>\n",
       "      <th>...</th>\n",
       "      <th>ROAD_SURFACE</th>\n",
       "      <th>ROAD_WET</th>\n",
       "      <th>NUM_LANES</th>\n",
       "      <th>TRAFFIC_CTRL</th>\n",
       "      <th>SPD_LIM</th>\n",
       "      <th>URBAN</th>\n",
       "      <th>LIGHT</th>\n",
       "      <th>STREET_LIGHT</th>\n",
       "      <th>WEATHER_A</th>\n",
       "      <th>WEATHER_B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>F</td>\n",
       "      <td>Vehicle(s)+Pedestrian(s)</td>\n",
       "      <td>Christmas/New Year</td>\n",
       "      <td>Northland</td>\n",
       "      <td>1688160</td>\n",
       "      <td>6101368</td>\n",
       "      <td>KERIKERI INLET ROAD</td>\n",
       "      <td>PA ROAD</td>\n",
       "      <td>Current location</td>\n",
       "      <td>...</td>\n",
       "      <td>Sealed</td>\n",
       "      <td>Dry</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>80</td>\n",
       "      <td>Openroad</td>\n",
       "      <td>Dark</td>\n",
       "      <td>On</td>\n",
       "      <td>Fine</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>F</td>\n",
       "      <td>Vehicle(s)+Pedestrian(s)</td>\n",
       "      <td>Christmas/New Year</td>\n",
       "      <td>Northland</td>\n",
       "      <td>1642352</td>\n",
       "      <td>6126632</td>\n",
       "      <td>ORURU ROAD</td>\n",
       "      <td>RYDER ROAD</td>\n",
       "      <td>Current location</td>\n",
       "      <td>...</td>\n",
       "      <td>Sealed</td>\n",
       "      <td>Dry</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>100</td>\n",
       "      <td>Openroad</td>\n",
       "      <td>Dark</td>\n",
       "      <td>None</td>\n",
       "      <td>Fine</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>F</td>\n",
       "      <td>Multi vehicle</td>\n",
       "      <td>Christmas/New Year</td>\n",
       "      <td>Bay of Plenty</td>\n",
       "      <td>1942531</td>\n",
       "      <td>5794171</td>\n",
       "      <td>THORNTON ROAD</td>\n",
       "      <td>POWDRELL ROAD</td>\n",
       "      <td>Current location</td>\n",
       "      <td>...</td>\n",
       "      <td>Sealed</td>\n",
       "      <td>Dry</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>100</td>\n",
       "      <td>Openroad</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>None</td>\n",
       "      <td>Fine</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>F</td>\n",
       "      <td>Multi vehicle</td>\n",
       "      <td>None</td>\n",
       "      <td>Canterbury</td>\n",
       "      <td>1564498</td>\n",
       "      <td>5161943</td>\n",
       "      <td>SH 75</td>\n",
       "      <td>RIFLE RANGE CV</td>\n",
       "      <td>Current location</td>\n",
       "      <td>...</td>\n",
       "      <td>Sealed</td>\n",
       "      <td>Wet</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>100</td>\n",
       "      <td>Openroad</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fine</td>\n",
       "      <td>Strong Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>F</td>\n",
       "      <td>Vehicle(s)+Pedestrian(s)</td>\n",
       "      <td>None</td>\n",
       "      <td>Otago</td>\n",
       "      <td>1313029</td>\n",
       "      <td>4986865</td>\n",
       "      <td>SH 8</td>\n",
       "      <td>AIRPORT ROAD</td>\n",
       "      <td>Current location</td>\n",
       "      <td>...</td>\n",
       "      <td>Sealed</td>\n",
       "      <td>Dry</td>\n",
       "      <td>2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>100</td>\n",
       "      <td>Openroad</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fine</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRASH_YEAR CRASH_SEV                 MULTI_VEH             HOLIDAY  \\\n",
       "0        2017         F  Vehicle(s)+Pedestrian(s)  Christmas/New Year   \n",
       "1        2017         F  Vehicle(s)+Pedestrian(s)  Christmas/New Year   \n",
       "2        2017         F             Multi vehicle  Christmas/New Year   \n",
       "3        2017         F             Multi vehicle                None   \n",
       "4        2017         F  Vehicle(s)+Pedestrian(s)                None   \n",
       "\n",
       "         LG_REGION_DESC  EASTING  NORTHING          CRASH_LOCN1  \\\n",
       "0  Northland             1688160   6101368  KERIKERI INLET ROAD   \n",
       "1  Northland             1642352   6126632           ORURU ROAD   \n",
       "2  Bay of Plenty         1942531   5794171        THORNTON ROAD   \n",
       "3  Canterbury            1564498   5161943                SH 75   \n",
       "4  Otago                 1313029   4986865                 SH 8   \n",
       "\n",
       "      CRASH_LOCN2  OUTDTD_LOCN_DESC     ...       ROAD_SURFACE ROAD_WET  \\\n",
       "0         PA ROAD  Current location     ...             Sealed      Dry   \n",
       "1      RYDER ROAD  Current location     ...             Sealed      Dry   \n",
       "2   POWDRELL ROAD  Current location     ...             Sealed      Dry   \n",
       "3  RIFLE RANGE CV  Current location     ...             Sealed      Wet   \n",
       "4    AIRPORT ROAD  Current location     ...             Sealed      Dry   \n",
       "\n",
       "  NUM_LANES  TRAFFIC_CTRL SPD_LIM     URBAN     LIGHT STREET_LIGHT  WEATHER_A  \\\n",
       "0         2           N/A      80  Openroad      Dark           On       Fine   \n",
       "1         2           N/A     100  Openroad      Dark         None       Fine   \n",
       "2         2           N/A     100  Openroad  Overcast         None       Fine   \n",
       "3         2           N/A     100  Openroad  Overcast      Unknown       Fine   \n",
       "4         2           N/A     100  Openroad  Overcast      Unknown       Fine   \n",
       "\n",
       "     WEATHER_B  \n",
       "0      Unknown  \n",
       "1      Unknown  \n",
       "2      Unknown  \n",
       "3  Strong Wind  \n",
       "4      Unknown  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View schema of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRASH_YEAR: integer (nullable = true)\n",
      " |-- CRASH_SEV: string (nullable = true)\n",
      " |-- MULTI_VEH: string (nullable = true)\n",
      " |-- HOLIDAY: string (nullable = true)\n",
      " |-- LG_REGION_DESC: string (nullable = true)\n",
      " |-- EASTING: integer (nullable = true)\n",
      " |-- NORTHING: integer (nullable = true)\n",
      " |-- CRASH_LOCN1: string (nullable = true)\n",
      " |-- CRASH_LOCN2: string (nullable = true)\n",
      " |-- OUTDTD_LOCN_DESC: string (nullable = true)\n",
      " |-- CRASH_RP_RS: integer (nullable = true)\n",
      " |-- INTERSECTION: string (nullable = true)\n",
      " |-- JUNCTION_TYPE: string (nullable = true)\n",
      " |-- CR_RD_SIDE_RD: integer (nullable = true)\n",
      " |-- CRASH_DIRN_DESC: string (nullable = true)\n",
      " |-- CRASH_DIST: integer (nullable = true)\n",
      " |-- CRASH_RP_DIRN_DESC: string (nullable = true)\n",
      " |-- DIRN_ROLE1_DESC: string (nullable = true)\n",
      " |-- CRASH_RP_DISP: integer (nullable = true)\n",
      " |-- CRASH_SH_DESC: string (nullable = true)\n",
      " |-- CRASH_RP_SH: string (nullable = true)\n",
      " |-- CRASH_RP_NEWS_DESC: string (nullable = true)\n",
      " |-- INTSN_MIDBLOCK: string (nullable = true)\n",
      " |-- FLAT_HILL: string (nullable = true)\n",
      " |-- ROAD_CHARACTER: string (nullable = true)\n",
      " |-- ROAD_CURVATURE: string (nullable = true)\n",
      " |-- ROAD_LANE: string (nullable = true)\n",
      " |-- ROAD_MARKINGS: string (nullable = true)\n",
      " |-- ROAD_SURFACE: string (nullable = true)\n",
      " |-- ROAD_WET: string (nullable = true)\n",
      " |-- NUM_LANES: integer (nullable = true)\n",
      " |-- TRAFFIC_CTRL: string (nullable = true)\n",
      " |-- SPD_LIM: integer (nullable = true)\n",
      " |-- URBAN: string (nullable = true)\n",
      " |-- LIGHT: string (nullable = true)\n",
      " |-- STREET_LIGHT: string (nullable = true)\n",
      " |-- WEATHER_A: string (nullable = true)\n",
      " |-- WEATHER_B: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Data Quality Verification\n",
    "The data quality of the data set seems to be fairly high. Only three out of 38 variables have missing data (see the result of the code chunk below).\n",
    "\n",
    "We also noticed that there are some variables have high proportion of *\"Unknown\"* and zero values which may result in such variables being identified as least important variables, thus excluded in later stages of our work.\n",
    "\n",
    "Apart from minor data issues mentioned above, we found nothing of concern regarding the data quality of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col, regexp_replace\n",
    "\n",
    "# Use spark to calculate the number of missing values for each column and convert the result to pandas.\n",
    "# Note: the result will contain a single row with 38 columns, small enough to be handled by pandas in memory\n",
    "missing_values = pd.concat(\n",
    "    [\n",
    "        df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).toPandas().transpose(),\n",
    "        df.select([count(when(col(c) == \" \", c)).alias(c) for c in df.columns]).toPandas().transpose()\n",
    "    ],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "missing_values.columns = [\"null\", \"whitespace\"]\n",
    "\n",
    "missing_values[\"total\"] = df.count()\n",
    "missing_values[\"missing\"] = missing_values[\"null\"] + missing_values[\"whitespace\"]\n",
    "missing_values[\"percent\"] = missing_values[\"missing\"] / missing_values[\"total\"] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>null</th>\n",
       "      <th>whitespace</th>\n",
       "      <th>total</th>\n",
       "      <th>missing</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRASH_DIRN_DESC</th>\n",
       "      <td>0</td>\n",
       "      <td>35316</td>\n",
       "      <td>104032</td>\n",
       "      <td>35316</td>\n",
       "      <td>33.947247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROAD_LANE</th>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>104032</td>\n",
       "      <td>54</td>\n",
       "      <td>0.051907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CR_RD_SIDE_RD</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>104032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 null  whitespace   total  missing    percent\n",
       "CRASH_DIRN_DESC     0       35316  104032    35316  33.947247\n",
       "ROAD_LANE           0          54  104032       54   0.051907\n",
       "CR_RD_SIDE_RD       1           0  104032        1   0.000961"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show columns that have missing values\n",
    "missing_values.loc[missing_values['percent'] > 0].sort_values(\"percent\", ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Selection\n",
    "A variable called **OUTDTD_LOCN_DESC** specifies whether a certain crash record has an outdated location or not. A crash is said to have an outdated location where the road might have moved or does not exist anymore. We decided to exclude outdated records from our data set because the data may no longer be valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104006\n"
     ]
    }
   ],
   "source": [
    "# Exclude outdated data\n",
    "crash_data = df.filter(\"OUTDTD_LOCN_DESC <> 'Outdated Location'\")\n",
    "\n",
    "print(crash_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Data Cleansing\n",
    "In section 2.4, we identified three variables with missing values. **CRASH_DIRN_DESC** and **ROAD_LANE** both have white spaces, while **CR_RD_SIDE_RD** has null values. We decided to impute white spaces with text constant *\"Unknown\"* and discard records with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104005\n"
     ]
    }
   ],
   "source": [
    "# Drop records with null values\n",
    "crash_data = crash_data.na.drop()\n",
    "\n",
    "# Impute white spaces with text constant \"Unknown\"\n",
    "crash_data = crash_data.withColumn(\"ROAD_LANE\", regexp_replace(crash_data[\"ROAD_LANE\"], \" \", \"Unknown\"))\n",
    "crash_data = crash_data.withColumn(\"CRASH_DIRN_DESC\", regexp_replace(crash_data[\"CRASH_DIRN_DESC\"], \" \", \"Unknown\"))\n",
    "\n",
    "# Check the number of remaining rows\n",
    "print(crash_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|ROAD_LANE|count|\n",
      "+---------+-----+\n",
      "|  Unknown|   54|\n",
      "|        O|  674|\n",
      "|        1|14251|\n",
      "|        2|89026|\n",
      "+---------+-----+\n",
      "\n",
      "+---------------+-----+\n",
      "|CRASH_DIRN_DESC|count|\n",
      "+---------------+-----+\n",
      "|        Unknown|35295|\n",
      "|          South|20977|\n",
      "|           East|13574|\n",
      "|           West|13554|\n",
      "|          North|20605|\n",
      "+---------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crash_data.groupBy(\"ROAD_LANE\").count().show()\n",
    "crash_data.groupBy(\"CRASH_DIRN_DESC\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 New Data Construction\n",
    "In an attempt to reduce the granularity within our data set, we decided to reclassify two variables (**LIGHT** and **CRASH_SEV**) into two new variables (**DARK_LIGHT** and **FATAL_OR_SERIOUS**).\n",
    "\n",
    "**DARK_LIGHT** is a categorical variable derived from **LIGHT** which tells us how much natural light was around the environment when the crash happened. Possible values of *Light*, *Dark* or *Unknown*.\n",
    "\n",
    "**FATAL_OR_SERIOUS** is a boolean flag derived from **CRASH_SEV** which tells us whether a record is fatal or serious injury related crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_data = crash_data.withColumn(\n",
    "    \"DARK_LIGHT\",\n",
    "    when(\n",
    "        crash_data[\"LIGHT\"].isin([\"Bright Sun\", \"Overcast\"]),\n",
    "        \"Light\"\n",
    "    ).otherwise(\n",
    "        when(\n",
    "            crash_data[\"LIGHT\"].isin([\"Dark\", \"Twilight\"]),\n",
    "            \"Dark\"\n",
    "        ).otherwise(\"Unknown\")\n",
    "    )\n",
    ")\n",
    "\n",
    "crash_data = crash_data.withColumn(\n",
    "    \"FATAL_OR_SERIOUS\",\n",
    "    when(\n",
    "        crash_data[\"CRASH_SEV\"].isin([\"F\", \"S\"]),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|DARK_LIGHT|count|\n",
      "+----------+-----+\n",
      "|   Unknown|  214|\n",
      "|     Light|69535|\n",
      "|      Dark|34256|\n",
      "+----------+-----+\n",
      "\n",
      "+----------------+-----+\n",
      "|FATAL_OR_SERIOUS|count|\n",
      "+----------------+-----+\n",
      "|               1| 6915|\n",
      "|               0|97090|\n",
      "+----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crash_data.groupBy(\"DARK_LIGHT\").count().show()\n",
    "crash_data.groupBy(\"FATAL_OR_SERIOUS\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Data Integration\n",
    "As previously mentioned in section 2.2, the data set used in this work was sourced from three CSV files. We performed data integration step by importing all three files using spark's read csv function and combining them into a single data frame.\n",
    "\n",
    "We let spark's read csv function automatically determine the data type for each column by setting *inferSchema* flag to *True* and confirmed that data type for each column was correctly assigned.\n",
    "\n",
    "No issues were encountered during the execution of this step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Data Formatting\n",
    "The creation of new variables (**DARK_LIGHT** and **FATAL_OR_SERIOUS**) which are derived from existing variables (**LIGHT** and **CRASH_SEV**) means that **LIGHT** and **CRASH_SEV** would have to be excluded from our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CRASH_YEAR: integer (nullable = true)\n",
      " |-- MULTI_VEH: string (nullable = true)\n",
      " |-- HOLIDAY: string (nullable = true)\n",
      " |-- LG_REGION_DESC: string (nullable = true)\n",
      " |-- EASTING: integer (nullable = true)\n",
      " |-- NORTHING: integer (nullable = true)\n",
      " |-- CRASH_LOCN1: string (nullable = true)\n",
      " |-- CRASH_LOCN2: string (nullable = true)\n",
      " |-- OUTDTD_LOCN_DESC: string (nullable = true)\n",
      " |-- CRASH_RP_RS: integer (nullable = true)\n",
      " |-- INTERSECTION: string (nullable = true)\n",
      " |-- JUNCTION_TYPE: string (nullable = true)\n",
      " |-- CR_RD_SIDE_RD: integer (nullable = true)\n",
      " |-- CRASH_DIRN_DESC: string (nullable = true)\n",
      " |-- CRASH_DIST: integer (nullable = true)\n",
      " |-- CRASH_RP_DIRN_DESC: string (nullable = true)\n",
      " |-- DIRN_ROLE1_DESC: string (nullable = true)\n",
      " |-- CRASH_RP_DISP: integer (nullable = true)\n",
      " |-- CRASH_SH_DESC: string (nullable = true)\n",
      " |-- CRASH_RP_SH: string (nullable = true)\n",
      " |-- CRASH_RP_NEWS_DESC: string (nullable = true)\n",
      " |-- INTSN_MIDBLOCK: string (nullable = true)\n",
      " |-- FLAT_HILL: string (nullable = true)\n",
      " |-- ROAD_CHARACTER: string (nullable = true)\n",
      " |-- ROAD_CURVATURE: string (nullable = true)\n",
      " |-- ROAD_LANE: string (nullable = true)\n",
      " |-- ROAD_MARKINGS: string (nullable = true)\n",
      " |-- ROAD_SURFACE: string (nullable = true)\n",
      " |-- ROAD_WET: string (nullable = true)\n",
      " |-- NUM_LANES: integer (nullable = true)\n",
      " |-- TRAFFIC_CTRL: string (nullable = true)\n",
      " |-- SPD_LIM: integer (nullable = true)\n",
      " |-- URBAN: string (nullable = true)\n",
      " |-- STREET_LIGHT: string (nullable = true)\n",
      " |-- WEATHER_A: string (nullable = true)\n",
      " |-- WEATHER_B: string (nullable = true)\n",
      " |-- DARK_LIGHT: string (nullable = false)\n",
      " |-- FATAL_OR_SERIOUS: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exclude variables that we used to derive DARK_LIGHT and FATAL_OR_SERIOUS variables from\n",
    "crash_data = crash_data.drop(\"LIGHT\", \"CRASH_SEV\")\n",
    "\n",
    "# Confirm data types of new variables\n",
    "crash_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then encode all categorical variables in our data set using *StringIndexer* class available in *pyspark.ml.feature* package. Categorical variable encoding is needed because most machine learning models cannot handle categorical variables unless they are converted to numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer, OneHotEncoder, StringIndexer\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of categorical columns\n",
    "cat_cols = [f.name for f in crash_data.schema.fields if f.dataType.simpleString() == \"string\"]\n",
    "\n",
    "# Get list of non-categorical columns and remove our target variable from the list\n",
    "noncat_cols = [f.name for f in crash_data.schema.fields if f.dataType.simpleString() != \"string\"]\n",
    "noncat_cols.remove(\"FATAL_OR_SERIOUS\")\n",
    "\n",
    "# Build StringIndexer stages\n",
    "strIdx = [StringIndexer(inputCol = c, outputCol = \"STRIDX_\" + c) for c in cat_cols]\n",
    "\n",
    "pipe = Pipeline(stages = strIdx)\n",
    "\n",
    "indexed_data = pipe.fit(crash_data).transform(crash_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
